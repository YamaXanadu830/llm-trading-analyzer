#!/usr/bin/env python3
"""
PAå½¢æ€åˆ†æå™¨ - åŸºäºLLMçš„Al Brooksä»·æ ¼è¡Œä¸ºå½¢æ€è¯†åˆ«
è¿™æ˜¯æ•´ä¸ªç³»ç»Ÿçš„æ ¸å¿ƒæ¨¡å—ï¼Œåˆ©ç”¨LLMç†è§£å’Œåˆ†æKçº¿å½¢æ€
"""

import json
import re
from typing import Dict, List, Optional, Any
import pandas as pd
from datetime import datetime

from .pa_prompts import PA_Prompts, PATTERN_TYPES
from .pa_kline_analyzer import PA_KLineAnalyzer


class PA_PatternAnalyzer:
    """åŸºäºLLMçš„ä»·æ ¼è¡Œä¸ºå½¢æ€åˆ†æå™¨"""
    
    def __init__(self, llm_client=None, model_name: str = "claude"):
        """
        åˆå§‹åŒ–å½¢æ€åˆ†æå™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆæš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿï¼‰
            model_name: æ¨¡å‹åç§°
        """
        self.llm_client = llm_client
        self.model_name = model_name
        self.analysis_history = []  # åˆ†æå†å²è®°å½•
        
        # åˆå§‹åŒ–PAç­–ç•¥çº§åˆ«Kçº¿åˆ†æå™¨ - é˜¶æ®µ2å¢å¼ºé…ç½®
        from .pa_kline_analyzer import PAAnalysisConfig
        pa_config = PAAnalysisConfig(
            # æ ¸å¿ƒå‚æ•°
            k_line_value=15,
            risk_reward_ratio=2.0,
            
            # é˜¶æ®µ2å¢å¼ºï¼šå½±çº¿è¿‡æ»¤å‚æ•°
            wick_ratio=0.33,               # å¯ç”¨å½±çº¿è¿‡æ»¤
            separate_wick_filter=False,    # ä½¿ç”¨ç»Ÿä¸€å½±çº¿è¿‡æ»¤æ¨¡å¼
            max_upper_wick_ratio=0.4,     # ä¸Šå½±çº¿æœ€å¤§æ¯”ä¾‹ï¼ˆç‹¬ç«‹æ¨¡å¼æ—¶ç”Ÿæ•ˆï¼‰
            max_lower_wick_ratio=0.4,     # ä¸‹å½±çº¿æœ€å¤§æ¯”ä¾‹ï¼ˆç‹¬ç«‹æ¨¡å¼æ—¶ç”Ÿæ•ˆï¼‰
            
            # é˜¶æ®µ2å¢å¼ºï¼šATRè¿‡æ»¤å‚æ•°
            enable_atr_filter=True,        # å¯ç”¨ATRè¿‡æ»¤
            atr_period=14,
            atr_multiplier=1.0,
            atr_filter_mode="moderate",    # ä¸­ç­‰è¿‡æ»¤æ¨¡å¼
            
            # é˜¶æ®µ2å¢å¼ºï¼šç»„åˆè¿‡æ»¤ç­–ç•¥
            require_both_filters=False,    # ORç»„åˆç­–ç•¥ï¼ˆè‡³å°‘ä¸€ä¸ªè¿‡æ»¤å™¨é€šè¿‡ï¼‰
            min_signal_strength="weak",    # æœ€å°ä¿¡å·å¼ºåº¦è¦æ±‚
            
            # é˜¶æ®µ2å¢å¼ºï¼šç»Ÿè®¡å’Œè°ƒè¯•
            enable_filter_stats=True,      # å¯ç”¨è¿‡æ»¤ç»Ÿè®¡
            debug_filter_details=False     # è°ƒè¯•æ¨¡å¼å…³é—­
        )
        self.kline_analyzer = PA_KLineAnalyzer(config=pa_config)
        
        # LLMåˆ†æå‚æ•°
        self.max_tokens = 1500
        self.temperature = 0.3  # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿åˆ†æä¸€è‡´æ€§
        
        print(f"âœ… PAå½¢æ€åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {model_name})")
    
    def analyze_pattern(self, ohlc_data: pd.DataFrame, 
                       timeframe: str = "15min",
                       pattern_type: Optional[str] = None,
                       context: Optional[str] = None) -> Dict[str, Any]:
        """
        åˆ†æä»·æ ¼è¡Œä¸ºå½¢æ€
        
        Args:
            ohlc_data: OHLCæ•°æ®DataFrame
            timeframe: æ—¶é—´å‘¨æœŸ
            pattern_type: ç‰¹å®šå½¢æ€ç±»å‹ï¼ˆå¯é€‰ï¼‰
            context: é¢å¤–çš„åˆ†æä¸Šä¸‹æ–‡
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        if ohlc_data.empty:
            return self._create_empty_result("æ— æ•°æ®å¯åˆ†æ")
        
        try:
            # ğŸš¨ æ–°å¢ï¼šçœŸå®Kçº¿å½¢æ€åˆ†æ
            print("ğŸ” æ‰§è¡ŒçœŸå®Kçº¿å½¢æ€åˆ†æ...")
            kline_analysis = self.kline_analyzer.analyze_kline_data(ohlc_data)
            
            # æ ¼å¼åŒ–æ•°æ®ä¸ºLLMå¯è¯»æ ¼å¼ï¼ˆåŒ…å«Kçº¿ç‰¹å¾ï¼‰
            llm_data = self._format_data_with_kline_features(ohlc_data, kline_analysis)
            
            # æ„å»ºåˆ†ææç¤ºè¯
            full_prompt = self._build_analysis_prompt(
                llm_data, timeframe, pattern_type, context
            )
            
            # è°ƒç”¨LLMåˆ†æ
            llm_response = self._call_llm(full_prompt, len(ohlc_data))
            
            # å¦‚æœæ²¡æœ‰LLMå“åº”ï¼Œè·³è¿‡å½¢æ€åˆ†æ
            if llm_response is None:
                # ç›´æ¥è¿”å›Kçº¿åˆ†æç»“æœï¼Œä¸åšå½¢æ€è¯†åˆ«
                return self._create_kline_only_analysis(kline_analysis, ohlc_data)
            else:
                # è§£æåˆ†æç»“æœ
                analysis_result = self._parse_llm_response(llm_response)
                
                # ğŸš¨ æ–°å¢ï¼šåŸºäºçœŸå®Kçº¿åˆ†æå¢å¼ºç»“æœ
                analysis_result = self._enhance_with_real_analysis(
                    analysis_result, kline_analysis, ohlc_data, timeframe
                )
            
            # è®°å½•åˆ†æå†å²
            self._record_analysis(analysis_result, ohlc_data, timeframe)
            
            return analysis_result
            
        except Exception as e:
            error_msg = f"å½¢æ€åˆ†æå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return self._create_empty_result(error_msg)
    
    def batch_analyze(self, data_windows: List[pd.DataFrame],
                     timeframe: str = "15min",
                     pattern_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†æå¤šä¸ªæ•°æ®çª—å£
        
        Args:
            data_windows: æ•°æ®çª—å£åˆ—è¡¨
            timeframe: æ—¶é—´å‘¨æœŸ
            pattern_type: ç‰¹å®šå½¢æ€ç±»å‹
            
        Returns:
            List[Dict]: åˆ†æç»“æœåˆ—è¡¨
        """
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡åˆ†æ {len(data_windows)} ä¸ªæ•°æ®çª—å£...")
        
        results = []
        for i, window in enumerate(data_windows):
            print(f"   åˆ†æè¿›åº¦: {i+1}/{len(data_windows)}")
            
            result = self.analyze_pattern(window, timeframe, pattern_type)
            results.append(result)
            
            # é¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
            if i % 10 == 9:
                print(f"   å·²å®Œæˆ {i+1} ä¸ªçª—å£åˆ†æ...")
        
        print(f"âœ… æ‰¹é‡åˆ†æå®Œæˆï¼Œå…± {len(results)} ä¸ªç»“æœ")
        return results
    
    def _format_data_for_llm(self, df: pd.DataFrame, max_bars: int = 100) -> str:
        """
        å°†DataFrameæ ¼å¼åŒ–ä¸ºLLMå¯è¯»çš„æ–‡æœ¬æ ¼å¼
        
        Args:
            df: OHLCæ•°æ®
            max_bars: æœ€å¤§Kçº¿æ•°é‡
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ–‡æœ¬æ•°æ®
        """
        # é™åˆ¶æ•°æ®é‡ï¼Œé¿å…æç¤ºè¯è¿‡é•¿
        if len(df) > max_bars:
            df = df.tail(max_bars).reset_index(drop=True)
        
        lines = []
        for i, row in df.iterrows():
            time_str = row['datetime'].strftime('%m-%d %H:%M') if 'datetime' in row else f"K{i+1:03d}"
            line = f"{time_str}: O={row['open']:.5f}, H={row['high']:.5f}, L={row['low']:.5f}, C={row['close']:.5f}"
            lines.append(line)
        
        return "\n".join(lines)
    
    def _format_data_with_kline_features(self, df: pd.DataFrame, kline_analysis: Dict[str, Any], max_bars: int = 100) -> str:
        """
        å°†DataFrameå’ŒKçº¿ç‰¹å¾æ ¼å¼åŒ–ä¸ºLLMå¯è¯»çš„æ–‡æœ¬æ ¼å¼
        
        Args:
            df: OHLCæ•°æ®
            kline_analysis: Kçº¿åˆ†æç»“æœ
            max_bars: æœ€å¤§Kçº¿æ•°é‡
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ–‡æœ¬æ•°æ®
        """
        # é™åˆ¶æ•°æ®é‡ï¼Œé¿å…æç¤ºè¯è¿‡é•¿
        if len(df) > max_bars:
            df = df.tail(max_bars).reset_index(drop=True)
            kline_features = kline_analysis['kline_features'][-max_bars:]
        else:
            kline_features = kline_analysis['kline_features']
        
        lines = []
        lines.append("=== Kçº¿æ•°æ®ä¸å½¢æ€ç‰¹å¾åˆ†æ ===")
        
        for i, (row, feature) in enumerate(zip(df.iterrows(), kline_features)):
            _, data = row
            time_str = data['datetime'].strftime('%m-%d %H:%M') if 'datetime' in data else f"K{i+1:03d}"
            
            # åŸºç¡€ä»·æ ¼æ•°æ®
            price_line = f"{time_str}: O={data['open']:.5f}, H={data['high']:.5f}, L={data['low']:.5f}, C={data['close']:.5f}"
            
            # Kçº¿ç‰¹å¾
            feature_line = f"    ç±»å‹:{feature.kline_type.value} å¼ºåº¦:{feature.strength.value} "
            feature_line += f"å®ä½“:{feature.body_size:.1f}ç‚¹ ä¸Šå½±:{feature.upper_shadow:.1f}ç‚¹ ä¸‹å½±:{feature.lower_shadow:.1f}ç‚¹"
            
            if feature.is_reversal_signal:
                feature_line += " [åè½¬ä¿¡å·]"
            
            lines.append(price_line)
            lines.append(feature_line)
        
        # æ·»åŠ ç»„åˆåˆ†æ
        combinations = kline_analysis.get('combinations', [])
        if combinations:
            lines.append("\n=== åæ²¡æ¨¡å¼ ===")
            for combo in combinations:
                lines.append(f"K{combo.start_index:03d}-K{combo.end_index:03d}: {combo.pattern_name} ({combo.pattern_type}, ç½®ä¿¡åº¦:{combo.confidence:.1%})")
        
        # æ·»åŠ ç»Ÿè®¡æ‘˜è¦
        lines.append("\n=== ç»Ÿè®¡æ‘˜è¦ ===")
        lines.append(f"é˜³çº¿:{kline_analysis['bullish_count']}æ ¹, é˜´çº¿:{kline_analysis['bearish_count']}æ ¹")
        lines.append(f"åæ²¡æ¨¡å¼:{len(combinations)}ä¸ª")
        
        return "\n".join(lines)
    
    def _enhance_with_real_analysis(self, analysis_result: Dict[str, Any], 
                                  kline_analysis: Dict[str, Any], 
                                  ohlc_data: pd.DataFrame, 
                                  timeframe: str) -> Dict[str, Any]:
        """
        åŸºäºçœŸå®Kçº¿åˆ†æç»“æœå¢å¼ºåˆ†æç»“æœ
        
        Args:
            analysis_result: åŸºç¡€åˆ†æç»“æœ
            kline_analysis: Kçº¿åˆ†æç»“æœ
            ohlc_data: åŸå§‹æ•°æ®
            timeframe: æ—¶é—´å‘¨æœŸ
            
        Returns:
            Dict: å¢å¼ºåçš„ç»“æœ
        """
        # ğŸš¨ å‡çº§ï¼šä½¿ç”¨PAç­–ç•¥ä¿¡å·æ›¿ä»£ä¼ ç»Ÿåæ²¡æ¨¡å¼
        trading_signals = kline_analysis.get('trading_signals', [])
        combinations = kline_analysis.get('combinations', [])
        condition_statistics = kline_analysis.get('condition_statistics', {})
        
        # å°†PAç­–ç•¥ç»“æœè½¬æ¢ä¸ºå…¼å®¹çš„signal_barsæ ¼å¼
        signal_bars_with_info = []
        
        if trading_signals:
            # åŸºäºPAç­–ç•¥ä¿¡å·ç”Ÿæˆä¿¡å·Kçº¿ä¿¡æ¯
            for signal in trading_signals:
                signal_bars_with_info.append({
                    'index': signal['index'],
                    'type': 'pa_strategy_signal',
                    'pattern': signal['trade_condition'].value,
                    'strength': 'strong' if signal['is_combo_condition'] else 'moderate',
                    'description': signal['label_text']
                })
            analysis_result['signal_source'] = 'pa_strategy_signals'
        else:
            # å¦‚æœæ²¡æœ‰PAç­–ç•¥ä¿¡å·ï¼Œä½¿ç”¨æœ€æ–°çš„å‡ æ ¹Kçº¿
            total_bars = len(ohlc_data)
            kline_features = kline_analysis.get('kline_features', [])
            
            for i in range(max(0, total_bars-3), total_bars):
                if i < len(kline_features):
                    feature = kline_features[i]
                    signal_bars_with_info.append({
                        'index': feature.index,
                        'type': 'latest',
                        'pattern': feature.kline_type.value,
                        'strength': feature.strength.value,
                        'description': f"{feature.kline_type.value}({feature.strength.value})"
                    })
            analysis_result['signal_source'] = 'latest_bars'
        
        # å»é‡å¹¶æ’åº
        seen_indices = set()
        unique_signals = []
        for signal_info in sorted(signal_bars_with_info, key=lambda x: x['index']):
            if signal_info['index'] not in seen_indices:
                unique_signals.append(signal_info)
                seen_indices.add(signal_info['index'])
        
        # æ›´æ–°ä¿¡å·ä¿¡æ¯ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬æ¥å£ï¼‰
        analysis_result['signal_bars'] = [s['index'] for s in unique_signals]
        analysis_result['signal_bars_info'] = unique_signals
        
        # ğŸš¨ æ–°å¢ï¼šPAç­–ç•¥ä¸“ç”¨å­—æ®µ
        analysis_result['trading_signals'] = trading_signals
        analysis_result['condition_statistics'] = condition_statistics
        
        # æ·»åŠ PAç­–ç•¥åˆ†ææ‘˜è¦
        kline_summary = self.kline_analyzer.get_analysis_summary(kline_analysis)
        analysis_result['kline_analysis_summary'] = kline_summary
        
        # æ›´æ–°æè¿°ï¼ŒåŒ…å«PAç­–ç•¥åˆ†æç»“æœ
        if trading_signals:
            signal_types = list(set([s['trade_condition'].value for s in trading_signals]))
            signal_desc = "ã€".join(signal_types[:3])  # æœ€å¤šæ˜¾ç¤º3ç§ç±»å‹
            analysis_result['description'] = f"PAç­–ç•¥æ£€æµ‹åˆ°: {signal_desc} ç­‰{len(trading_signals)}ä¸ªä¿¡å·ã€‚" + analysis_result.get('description', '')
        else:
            analysis_result['description'] = f"PAç­–ç•¥åˆ†æ: {kline_analysis['bullish_count']}æ ¹é˜³çº¿, {kline_analysis['bearish_count']}æ ¹é˜´çº¿ï¼Œæœªæ£€æµ‹åˆ°äº¤æ˜“ä¿¡å·ã€‚"
        
        # æ›´æ–°å…ƒæ•°æ®
        analysis_result['real_kline_analysis'] = {
            'total_analysis': len(kline_analysis['kline_features']),
            'trading_signals_count': len(trading_signals),
            'conditions_triggered': sum(1 for count in condition_statistics.values() if count > 0),
            'latest_kline_type': kline_analysis['latest_kline'].kline_type.value if kline_analysis['latest_kline'] else 'unknown'
        }
        
        # ä¼ ç»Ÿçš„å¢å¼ºå¤„ç†
        analysis_result = self._enhance_analysis_result(analysis_result, ohlc_data, timeframe)
        
        return analysis_result
    
    def _build_analysis_prompt(self, llm_data: str, timeframe: str,
                              pattern_type: Optional[str], context: Optional[str]) -> str:
        """
        æ„å»ºå®Œæ•´çš„åˆ†ææç¤ºè¯
        
        Args:
            llm_data: æ ¼å¼åŒ–çš„æ•°æ®
            timeframe: æ—¶é—´å‘¨æœŸ
            pattern_type: å½¢æ€ç±»å‹
            context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            str: å®Œæ•´æç¤ºè¯
        """
        # åŸºç¡€æç¤ºè¯
        system_prompt = PA_Prompts.SYSTEM_PROMPT
        
        # åˆ†ææç¤ºè¯
        analysis_prompt = PA_Prompts.format_analysis_prompt(
            llm_data, timeframe, pattern_type
        )
        
        # æ·»åŠ ä¸Šä¸‹æ–‡
        if context:
            analysis_prompt += f"\n\nã€é¢å¤–ä¸Šä¸‹æ–‡ã€‘\n{context}"
        
        return f"{system_prompt}\n\n{analysis_prompt}"
    
    def _call_llm(self, prompt: str, data_length: int = 100) -> str:
        """
        è°ƒç”¨LLMè¿›è¡Œåˆ†æ
        
        Args:
            prompt: å®Œæ•´æç¤ºè¯
            
        Returns:
            str: LLMå“åº”
        """
        if self.llm_client:
            # çœŸå®çš„LLMè°ƒç”¨é€»è¾‘
            try:
                response = self.llm_client.generate(
                    prompt=prompt,
                    max_tokens=self.max_tokens,
                    temperature=self.temperature
                )
                return response
            except Exception as e:
                print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                return None
        else:
            print("âš ï¸ æœªé…ç½®LLMå®¢æˆ·ç«¯ï¼Œè·³è¿‡å½¢æ€åˆ†æ")
            return None
    
    def _create_kline_only_analysis(self, kline_analysis: Dict[str, Any], ohlc_data: pd.DataFrame) -> Dict[str, Any]:
        """ç›´æ¥è¿”å›Kçº¿åˆ†æç»“æœï¼Œè·³è¿‡LLMå½¢æ€è¯†åˆ«"""
        return kline_analysis
    
    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """
        è§£æLLMçš„JSONå“åº”
        
        Args:
            response: LLMåŸå§‹å“åº”
            
        Returns:
            Dict: è§£æåçš„ç»“æ„åŒ–ç»“æœ
        """
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ['pattern_type', 'confidence', 'trade_signal']
                for field in required_fields:
                    if field not in result:
                        result[field] = 'unknown' if field == 'pattern_type' else 0.0 if field == 'confidence' else 'none'
                
                return result
            else:
                raise ValueError("å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
                
        except Exception as e:
            print(f"âŒ è§£æLLMå“åº”å¤±è´¥: {e}")
            return self._create_empty_result(f"å“åº”è§£æå¤±è´¥: {str(e)}")
    
    def _enhance_analysis_result(self, result: Dict[str, Any], 
                               ohlc_data: pd.DataFrame, 
                               timeframe: str) -> Dict[str, Any]:
        """
        å¢å¼ºåˆ†æç»“æœï¼Œæ·»åŠ é¢å¤–ä¿¡æ¯
        
        Args:
            result: åŸºç¡€åˆ†æç»“æœ
            ohlc_data: åŸå§‹æ•°æ®
            timeframe: æ—¶é—´å‘¨æœŸ
            
        Returns:
            Dict: å¢å¼ºåçš„ç»“æœ
        """
        # æ·»åŠ å…ƒæ•°æ®
        result['metadata'] = {
            'analysis_time': datetime.now().isoformat(),
            'data_count': len(ohlc_data),
            'timeframe': timeframe,
            'price_range': {
                'high': float(ohlc_data['high'].max()),
                'low': float(ohlc_data['low'].min()),
                'latest_price': float(ohlc_data['close'].iloc[-1])
            }
        }
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡è¡¥å……
        result['technical_context'] = self._calculate_technical_context(ohlc_data)
        
        # å½¢æ€ç±»å‹ä¸­æ–‡åç§°
        if result['pattern_type'] in PATTERN_TYPES:
            result['pattern_name_cn'] = PATTERN_TYPES[result['pattern_type']]
        
        return result
    
    def _calculate_technical_context(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ä¸Šä¸‹æ–‡
        
        Args:
            df: OHLCæ•°æ®
            
        Returns:
            Dict: æŠ€æœ¯æŒ‡æ ‡ä¿¡æ¯
        """
        try:
            latest_close = df['close'].iloc[-1]
            
            # ç®€å•ç§»åŠ¨å¹³å‡
            sma_20 = df['close'].tail(20).mean() if len(df) >= 20 else latest_close
            sma_50 = df['close'].tail(50).mean() if len(df) >= 50 else latest_close
            
            # ä»·æ ¼ç›¸å¯¹ä½ç½®
            price_vs_sma20 = 'above' if latest_close > sma_20 else 'below'
            price_vs_sma50 = 'above' if latest_close > sma_50 else 'below'
            
            # æ³¢åŠ¨æ€§
            price_range = df['high'].max() - df['low'].min()
            volatility = (price_range / df['close'].mean()) * 100
            
            return {
                'sma_20': round(sma_20, 5),
                'sma_50': round(sma_50, 5),
                'price_vs_sma20': price_vs_sma20,
                'price_vs_sma50': price_vs_sma50,
                'volatility_percent': round(volatility, 2),
                'recent_range': round(price_range, 5)
            }
            
        except Exception as e:
            print(f"âš ï¸ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return {}
    
    def _create_empty_result(self, error_message: str) -> Dict[str, Any]:
        """
        åˆ›å»ºç©ºçš„åˆ†æç»“æœ
        
        Args:
            error_message: é”™è¯¯æ¶ˆæ¯
            
        Returns:
            Dict: ç©ºç»“æœ
        """
        return {
            'pattern_type': 'none',
            'confidence': 0.0,
            'trend_direction': 'unknown',
            'key_levels': [],
            'signal_bars': [],
            'trade_signal': 'none',
            'entry_price': 0.0,
            'stop_loss': 0.0,
            'target_price': 0.0,
            'risk_reward_ratio': 0.0,
            'description': error_message,
            'market_context': '',
            'probability_assessment': '',
            'error': True,
            'error_message': error_message
        }
    
    def _record_analysis(self, result: Dict[str, Any], 
                        ohlc_data: pd.DataFrame, timeframe: str) -> None:
        """
        è®°å½•åˆ†æå†å²
        
        Args:
            result: åˆ†æç»“æœ
            ohlc_data: æ•°æ®
            timeframe: æ—¶é—´å‘¨æœŸ
        """
        history_record = {
            'timestamp': datetime.now().isoformat(),
            'timeframe': timeframe,
            'data_count': len(ohlc_data),
            'pattern_type': result.get('pattern_type'),
            'confidence': result.get('confidence'),
            'trade_signal': result.get('trade_signal')
        }
        
        self.analysis_history.append(history_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.analysis_history) > 1000:
            self.analysis_history = self.analysis_history[-500:]
    
    def get_analysis_summary(self) -> Dict[str, Any]:
        """
        è·å–åˆ†æå†å²æ‘˜è¦
        
        Returns:
            Dict: æ‘˜è¦ç»Ÿè®¡
        """
        if not self.analysis_history:
            return {'total_analyses': 0}
        
        # ç»Ÿè®¡å„ç§å½¢æ€å‡ºç°é¢‘ç‡
        pattern_counts = {}
        signal_counts = {}
        
        for record in self.analysis_history:
            pattern = record['pattern_type']
            signal = record['trade_signal']
            
            pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
            signal_counts[signal] = signal_counts.get(signal, 0) + 1
        
        return {
            'total_analyses': len(self.analysis_history),
            'pattern_distribution': pattern_counts,
            'signal_distribution': signal_counts,
            'latest_analysis': self.analysis_history[-1]['timestamp']
        }


def test_pa_pattern_analyzer():
    """æµ‹è¯•PAå½¢æ€åˆ†æå™¨åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•PAå½¢æ€åˆ†æå™¨")
    print("=" * 50)
    
    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = PA_PatternAnalyzer()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'datetime': pd.date_range(start='2024-01-01 09:00', periods=50, freq='15min'),
            'open': [1.08000 + i * 0.0001 for i in range(50)],
            'high': [1.08000 + i * 0.0001 + 0.0005 for i in range(50)],
            'low': [1.08000 + i * 0.0001 - 0.0005 for i in range(50)],
            'close': [1.08000 + i * 0.0001 + (i % 3 - 1) * 0.0002 for i in range(50)]
        })
        
        # æµ‹è¯•å•æ¬¡åˆ†æ
        print("\nğŸ“Š æµ‹è¯•å•æ¬¡å½¢æ€åˆ†æ:")
        result = analyzer.analyze_pattern(test_data, "15min")
        
        print(f"   å½¢æ€ç±»å‹: {result['pattern_type']}")
        print(f"   ä¿¡å¿ƒåº¦: {result['confidence']}")
        print(f"   äº¤æ˜“ä¿¡å·: {result['trade_signal']}")
        print(f"   æè¿°: {result['description'][:100]}...")
        
        # æµ‹è¯•æ ¼å¼åŒ–åŠŸèƒ½
        print("\nğŸ”¤ æµ‹è¯•æ•°æ®æ ¼å¼åŒ–:")
        formatted = analyzer._format_data_for_llm(test_data.head(5))
        print(f"   æ ¼å¼åŒ–é•¿åº¦: {len(formatted)} å­—ç¬¦")
        print(f"   é¦–è¡Œ: {formatted.split()[0]}")
        
        # æµ‹è¯•åˆ†ææ‘˜è¦
        print("\nğŸ“‹ æµ‹è¯•åˆ†ææ‘˜è¦:")
        summary = analyzer.get_analysis_summary()
        print(f"   æ€»åˆ†ææ¬¡æ•°: {summary['total_analyses']}")
        print(f"   å½¢æ€åˆ†å¸ƒ: {summary.get('pattern_distribution', {})}")
        
        print("\nâœ… PAå½¢æ€åˆ†æå™¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_pa_pattern_analyzer()